//#define DBG_RenderPreemptColl
//
//#define KAM_POSITIVE_SLICE		vrai
//#define KAM_NEGATIVE_SLICE	faux
//
//// with this, inside each slice a second raycast is sent to try and find a corner face
//#define KAM_FIND_FACE_INTERSECTION


/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////	
////	Kam_ComputeRedux
////
////	Compute one reduction based on angle of this found protrusion (peak)
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////	
//
//procedure float Kam_ComputeRedux
//( 
//	vector tv_dirOfCam, 
//	float tf_distOfCam, 
//	vector tv_dirOfPeak, 
//	float tf_distOfPeak,
//	float tf_angleAtExtremity,
//	float tf_extremityRatio
//)
//{
//	float tf_dot
//	float tf_redux
//	float tf_angle				// angle bw peak and cam directions
//	float tf_anglePosRatio	// 0 means angle is at tf_angleAtExtremity,   1 means it at camera dir
//	float tf_ratioSpan			// ratio span from 1.0 at camera dir to tf_extremityRatio at most extreem angle
//	float tf_angleFactor		// final angle factor to multiply redux
//
//
//	tf_ratioSpan = 1.0 - tf_extremityRatio
//	tf_dot = MATH_VecDotProduct( tv_dirOfPeak, tv_dirOfCam )
//	tf_angle = MATH_ACos(tf_dot)
//	
//	tf_anglePosRatio = (tf_angleAtExtremity - tf_angle) / tf_angleAtExtremity
//	
//	tf_angleFactor = (tf_anglePosRatio * tf_ratioSpan) + tf_extremityRatio
//	//tf_angleFactor *= tf_angleFactor	// square the factor but since it's < 1.0 it makes it smaller
//
//	tf_redux = (tf_distOfCam - tf_distOfPeak) * tf_angleFactor
//	
//	return tf_redux
//}
//
//
//
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////	
////	Kam_AnalyzeOneSlice
////
////	Analyse what is inside one slice around the camera
////	If there is a peak (protrusion) found return true, otherwise return false
////		
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////	
//
//procedure int Kam_AnalyzeOneSlice
//(
//	vector		tv_cam_target,			// former tv__pos_tete_kong
//	vector		tv_sliceEdgePos,		// former tv__real_cam_col
//	vector		tv_probePos,
//	//float			tf_probeAngle,			// slice is towards positive rotation
//	int				tb_positiveSide,		// the slice is towards positive rotation
//	byref vector tv_peak,
//	byref vector tv_probeCol
//)
//{
//	object	to_gao
//	vector	tv_temp,tv_temp1
//	float		tf_temp,tf_temp1
//	
//	vector	tv_sliceEdgeVec
//	vector	tv_sliceEdgeDir
////	vector	tv_cam_pos			// collision where the camera is or real cam pos
//	float		tf_real_cam_dst		// corresponding real camera distance to kong's head
//	vector	tv_probeVec			// probe vector looking out for obstacles
////	float		tf_probeAngle			// angle offset (from the current sight) to be tested 
//	object	to_gaoProbeCol		// gao colliding along the probe
//	object	to_gaoSliceCol		// gao colliding bw cam and probe collision
////	vector	tv_probeCol				// position of the collision of the probe with an obstacle
//	vector	tv_probeColFNormal	// normal of the colliding face
//	vector	tv_probeColFNorm_in	// prependicular to probe coll normal pointing towards camera
//	vector	tv_probeColFNormalHoriz	// normal of the colliding face with z component set to 0
//	vector	tv_sep_to_pb			// vector that goes from the slice edge position (tv_sliceEdgePos) to the probe's collision position (tv_probeCol)
//	vector	tv_sep_to_pb_DirHoriz
//	// inter collision is the collision bw cam pos and probe coll pos
//	vector	tv_interCol				// position of the inter collision
//	vector	tv_interColNormal		// face normal of inter collision
//	vector	tv_interColNorm_in	// perpendicual to inter collision normal pointing towards kong
//	float		tv_dotForLookout		// the lookout is the closest distance to the head from the collision found
//	
//	// result
//	float		tf_peakDst
//	int			ti_dbgStr	
//	float		tf_finalReduction		// in the end, how much should we take away from the original cam pos
//	
//	
//	//tv_cam_target = pop
//	//tv_cam_pos = pop
//	//tf_probeAngle = pop	// -0.5			// about 30 deg
//	
//	MATH_VecSetNull(tv_peak)
//	tf_finalReduction = 0.0		// will remain if no obstruction found or problem with computing an obstruction
//		
//	tv_sliceEdgeDir = tv_sliceEdgePos - tv_cam_target
//	tv_sliceEdgeDir = MATH_VecNormalize(tv_sliceEdgePos)
//	tv_probeVec = tv_probePos - tv_cam_target
//	
//	#ifdef DBG_RenderPreemptColl
//	DBG_RenderVector(tv_cam_target,tv_probeVec*1.2,color_bleu)
//	#endif
//	
//	//====================================
//	// check collision along probe
//	COL_SpecificCrossableSet(Gmat_RM_Traversable_par_Camera)
//	to_gaoProbeCol = COL_RayObject_Vector(tv_cam_target, tv_probeVec, all, OBJ_C_IdentityFlag_Anims, Ci_Filter_IdentityFlag, COL_C_Ray_on_ColMap_NoCrossable + COL_C_Ray_use_SpecificCrossableSet)
//	if (!to_gaoProbeCol)
//		return 0
//
//	tv_probeCol = COL_RayObject_PosGet()
//	tv_peak = tv_probeCol	// so far the best
//	
//	#ifdef DBG_RenderPreemptColl
//	DBG_RenderSphere(tv_probeCol,0.2,color_rouge)
//	#endif
//
//#ifndef KAM_FIND_FACE_INTERSECTION
//	return 1
//#endif
//
//	//========================================================================
//	// get the horizontal face-normal at the collision point
//	tv_probeColFNormal = COL_RayObject_NormalGet()
//	tv_probeColFNormalHoriz = tv_probeColFNormal
//	tv_probeColFNormalHoriz.z = 0.0
//	if (MATH_VecNull(tv_probeColFNormalHoriz))
//	{
//		// can this happen since camera is always looking pretty much horizontally !?
////		DBG_Warning("camera probe collided with flat face !?")
//		return 1
//	}
//	tv_probeColFNormalHoriz = MATH_VecNormalize(tv_probeColFNormalHoriz)
//	#ifdef DBG_RenderPreemptColl
//	DBG_RenderVector(tv_probeCol,tv_probeColFNormalHoriz,color_rouge)
//	#endif
//	
//	//========================================================================
//	// get a horizontal perpendicular pointing inside the slice
//	if (tb_positiveSide)
//	{
//		// pointing inside the slice is to the left	
//		tv_probeColFNorm_in = cvector(-tv_probeColFNormalHoriz.y, tv_probeColFNormalHoriz.x, 0.0)
//	}
//	else
//	{
//		// pointing inside the slice is to the right
//		tv_probeColFNorm_in = cvector(tv_probeColFNormalHoriz.y, -tv_probeColFNormalHoriz.x, 0.0)
//	}
//	#ifdef DBG_RenderPreemptColl
//	DBG_RenderVector(tv_probeCol,tv_probeColFNorm_in,color_jaune)
//	#endif
//
//	//========================================================================
//	// Get a horizontal dir from slice edge pos to probe collision
//	tv_sep_to_pb = tv_probeCol - tv_sliceEdgePos
//	tv_sep_to_pb_DirHoriz = tv_sep_to_pb
//	tv_sep_to_pb_DirHoriz.z = 0.0
//	if (MATH_VecNull(tv_sep_to_pb_DirHoriz))
//	{
//		// can this happen since camera is always looking pretty much horizontally !?
////		DBG_Warning("camera probe collided with flat face !?")
//		return 1
//	}
//	tv_sep_to_pb_DirHoriz = MATH_VecNormalize(tv_sep_to_pb_DirHoriz)
//	#ifdef DBG_RenderPreemptColl
//	DBG_RenderVector(tv_sliceEdgePos,tv_sep_to_pb_DirHoriz,color_jaune)
//	#endif
//
//	//========================================================================
//	// check if the colliding face normal is such that there is a closer obstruction coming
//	// ...
//	//
//	tv_dotForLookout = MATH_VecDotProduct(tv_probeColFNormalHoriz,tv_sep_to_pb_DirHoriz)
//	if (tv_dotForLookout > 0.0)
//	{
//		// there is a closer obstruction inside the slice
//		to_gaoSliceCol = COL_RayObject_Vector(tv_sliceEdgePos, tv_sep_to_pb, all, OBJ_C_IdentityFlag_Anims, Ci_Filter_IdentityFlag, COL_C_Ray_on_ColMap_NoCrossable + COL_C_Ray_use_SpecificCrossableSet)
//		if (!to_gaoSliceCol)
//			return 1
//	
//		tv_interCol = COL_RayObject_PosGet()
//		#ifdef DBG_RenderPreemptColl
//		DBG_RenderSphere(tv_interCol,0.2,color_rouge)				
//		#endif
//	
//		tv_interColNormal = COL_RayObject_NormalGet()
//		tv_interColNormal.z = 0.0
//		if (MATH_VecNull(tv_interColNormal))
//		{
//			// can this happen since camera is always looking pretty much horizontally !?
////			DBG_Warning("camera probe collided with flat face !?")
//			return 1
//		}
//		#ifdef DBG_RenderPreemptColl
//		DBG_RenderVector(tv_interCol,tv_interColNormal,color_rouge)
//		#endif
//		
//		if (tb_positiveSide)
//		{
//			// pointing inside the slice is to the left	
//			tv_interColNorm_in = cvector(tv_interColNormal.y, -tv_interColNormal.x, 0.0)
//		}
//		else
//		{
//			// pointing inside the slice is to the right
//			tv_interColNorm_in = cvector(-tv_interColNormal.y, tv_interColNormal.x, 0.0)					
//		}
//		#ifdef DBG_RenderPreemptColl
//		DBG_RenderVector(tv_interCol,tv_interColNorm_in,color_jaune)
//		#endif
//		
//		// find the intersection of the two colliding faces (or at least their orientation)
//		if (MATH_LIB_Intersection_Dir_Plane(tv_interCol, tv_interColNorm_in, tv_probeCol, -1*tv_probeColFNormalHoriz, tf_temp, tv_temp))
//		{
//			// consider only if it's inside the slice
//			if (MATH_VecDotProduct(tv_temp - tv_interCol,tv_interColNorm_in) > 0.0)
//			{
//				tv_peak = tv_temp
//				#ifdef DBG_RenderPreemptColl
//				DBG_RenderSphere(tv_temp,0.3,color_jaune)
//				#endif
//			}
//		}
//	}
//			
//	return 1
//}
//
//
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////	
//// 	Kam_GetReduxFromSlices
////
//// Analyse around the camera to find upcomming obstructing protrusions
////
//// Goals:
////
//// - Have a gradual reduction of the camera's distance because of an obstruction
//// - never find yourself behind a wall
//// 
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////	
//
//procedure float Kam_GetReduxFromSlices
//(
//	vector		tv_cam_target,
//	vector		tv_cam_pos,
//	int				ti_nbSlicesEachSide,
//	float			tf_angleSpan,
//	float 			tf_extremityRatio
//)
//{
//	float 		tf_maxRedux
//	float		tf_curRedux
//	float		tf_finalReduxRatio		// the ratio of what remains of the original distance (1.0 means no reduction)
//	vector	tv_dirOfRedux
//	vector	tv_posOfRedux			// for debug display
//	float		tf_closestTgtDst		// distance of the closest obstructing position (peak), the second raycast is based on that pos
//	int			ti_curSlice
//	vector	tv_sliceEdgeVec			// the slice edge is opposite the probe
//	vector	tv_sliceEdgePos
//	vector	tv_probeVec
//	vector	tv_probePos
//	vector	tv_probeCol					// position where there was a collision along the probe
//	vector	tv_rdx_cam_pos			// adjusted cam pos if there was obstruction with current cam pos
//	vector	tv_peak
//	
//	object	to_gao
//	float		tf_temp
//	float		tf_first_cam_dst		// camera distance to target when we started
//	vector	tv_tgt_to_cam
//	vector	tv_tgt_to_cam_dir
//	float		tf_sliceAngle
//	
//	vector tv_tgt_to_peak_dir
//	float tf_peakDst
//	vector tv_sliceEdgeDir
//
//
//	tv_tgt_to_cam = tv_cam_pos - tv_cam_target
//	tf_first_cam_dst = MATH_VecNorm(tv_tgt_to_cam)
//	tv_tgt_to_cam_dir = tv_tgt_to_cam / tf_first_cam_dst
//	tf_temp = ti_nbSlicesEachSide
//	tf_sliceAngle = tf_angleSpan / tf_temp
//	
//	#ifdef DBG_RenderPreemptColl
//	DBG_RenderVector(tv_cam_target, tv_tgt_to_cam*1.2, color_vert)		// *1.2 to avoid having the anhoying cone blocking the view
//	#endif
//	
//	//==============================================================
//	// first find if there is a redux on the current camera position
//	// find the collision with the real cam position
//	COL_SpecificCrossableSet(Gmat_RM_Traversable_par_Camera)
//	to_gao = COL_RayObject_Vector(tv_cam_target, tv_tgt_to_cam, all, OBJ_C_IdentityFlag_Anims, Ci_Filter_IdentityFlag, COL_C_Ray_on_ColMap_NoCrossable + COL_C_Ray_use_SpecificCrossableSet)
//	if (to_gao)
//	{
//		tv_rdx_cam_pos = COL_RayObject_PosGet()
//		tv_dirOfRedux =  tv_tgt_to_cam_dir
//		tf_temp = MATH_VecNorm(tv_rdx_cam_pos - tv_cam_target)
//		tf_curRedux = tf_first_cam_dst - tf_temp
//		tf_closestTgtDst = tf_temp
//		#ifdef DBG_RenderPreemptColl
//		DBG_RenderSphere(tv_rdx_cam_pos,0.2,color_rouge)
//		#endif
//	}
//	else
//	{
//		tv_rdx_cam_pos = tv_cam_pos
//		tv_dirOfRedux = tv_tgt_to_cam
//		tf_curRedux = 0.0
//		tf_closestTgtDst = MATH_VecNorm(tv_rdx_cam_pos)
//		#ifdef DBG_RenderPreemptColl
//		DBG_RenderSphere(tv_rdx_cam_pos,0.2,color_vert)
//		#endif
//	}
//	
//	tv_sliceEdgeVec = tv_rdx_cam_pos - tv_cam_target
//	tv_sliceEdgePos = tv_rdx_cam_pos
//	tf_maxRedux = tf_curRedux
//	tv_posOfRedux = tv_rdx_cam_pos
//	
//	//==============================================================
//	// Positive slices
//	for (ti_curSlice = 0; ti_curSlice < ti_nbSlicesEachSide; ti_curSlice++)
//	{
//		// rotate for next slice
//		tv_probeVec = MATH_VecRotate(tv_sliceEdgeVec, cvector(0,0,1), tf_sliceAngle)
//		tv_probePos = tv_cam_target + tv_probeVec
//		
//		if ( Kam_AnalyzeOneSlice( tv_cam_target, tv_sliceEdgePos, tv_probePos, KAM_POSITIVE_SLICE, tv_peak, tv_probeCol ) )
//		{
//			// a peak was found let's check for a bigger redux
//			
//			tv_tgt_to_peak_dir = tv_peak - tv_cam_target
//			//tv_tgt_to_peak_dir.z = 0
//			tf_peakDst = MATH_VecNorm(tv_tgt_to_peak_dir)
//			tv_tgt_to_peak_dir /= tf_peakDst
//
//			tf_curRedux = Kam_ComputeRedux( tv_tgt_to_cam_dir, tf_first_cam_dst, tv_tgt_to_peak_dir, tf_peakDst, tf_angleSpan, tf_extremityRatio )
//			
//			if (tf_curRedux > tf_maxRedux)
//			{
//				tf_maxRedux = tf_curRedux
//				tv_dirOfRedux = tv_tgt_to_peak_dir
//				tv_posOfRedux = tv_peak
//				tf_closestTgtDst = tf_peakDst
//			}
//			
//			#ifdef DBG_RenderPreemptColl
//			DBG_RenderSphere(tv_peak, 0.2,color_rose)
//			#endif
//		}
//		
//		//-------------------------------
//		// prepare next slice
//		tv_sliceEdgePos = tv_probePos
//		tv_sliceEdgeVec = tv_sliceEdgePos - tv_cam_target
//		// a test with those two lines of code to have a better chance of finding a peak
//		//tv_sliceEdgeVec = MATH_VecNormalize(tv_probePos - tv_cam_target) * tf_closestTgtDst
//		//tv_sliceEdgePos = tv_sliceEdgeVec + tv_cam_target
//	}
//	
//	//==============================================================
//	// switch to negative slices
//	tv_sliceEdgeVec = tv_rdx_cam_pos - tv_cam_target
//	tv_sliceEdgePos = tv_rdx_cam_pos
//
//	//==============================================================
//	// Negative slices
//	for (ti_curSlice = 0; ti_curSlice < ti_nbSlicesEachSide; ti_curSlice++)
//	{
//		// rotate for next slice
//		tv_probeVec = MATH_VecRotate(tv_sliceEdgeVec, cvector(0,0,1), -tf_sliceAngle)
//		tv_probePos = tv_cam_target + tv_probeVec
//		
//		if ( Kam_AnalyzeOneSlice( tv_cam_target, tv_sliceEdgePos, tv_probePos, KAM_NEGATIVE_SLICE, tv_peak, tv_probeCol ) )
//		{
//			// a peak was found let's check for a bigger redux
//			
//			tv_tgt_to_peak_dir = tv_peak - tv_cam_target
//			//tv_tgt_to_peak_dir.z = 0
//			tf_peakDst = MATH_VecNorm(tv_tgt_to_peak_dir)
//			tv_tgt_to_peak_dir /= tf_peakDst
//
//			tf_curRedux = Kam_ComputeRedux( tv_tgt_to_cam_dir, tf_first_cam_dst, tv_tgt_to_peak_dir, tf_peakDst, tf_angleSpan, tf_extremityRatio )
//			
//			if (tf_curRedux > tf_maxRedux)
//			{
//				tf_maxRedux = tf_curRedux
//				tv_dirOfRedux = tv_tgt_to_peak_dir
//				tv_posOfRedux = tv_peak
//			}
//			
//			#ifdef DBG_RenderPreemptColl
//			DBG_RenderSphere(tv_peak, 0.2,color_rose)
//			#endif
//		}
//		
//		//-------------------------------
//		// prepare next slice
//		tv_sliceEdgePos = tv_probePos
//		tv_sliceEdgeVec = tv_sliceEdgePos - tv_cam_target
//	}
//
//	if (tf_maxRedux > 0.0)
//	{
//		#ifdef DBG_RenderPreemptColl
//		DBG_RenderSphere(tv_posOfRedux, 0.3,color_cyan)		// the winner
//		#endif
//		tf_finalReduxRatio = 1.0 - (tf_maxRedux / tf_first_cam_dst)
//	}
//	else
//	{
//		tf_finalReduxRatio = 1.0
//	}
//	
//	return tf_finalReduxRatio
//}
//
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////	
//// 	Kam_CommitSuicide
////
//// Goals:
////
//// - Be able to suicide the camera 
//// 
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////	
//procedure_ultra void		Kam_CommitSuicide()
//{	
//	AI_TrackStop(0)
//	AI_TrackStop(1)
//	AI_TrackStop(2)
//	AI_TrackStop(3)
//	AI_TrackStop(4)	
//	OBJ_FlagInactiveSet(vrai)	
//}